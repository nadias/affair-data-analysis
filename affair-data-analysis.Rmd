---
title: "Affair-data-analysis"
author: "Nadia Soares"
date: "1/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setting up:

```{r}
library(ggplot2)
library(MASS)
library(texreg)
library(corrplot)
library(car)

smart.round <- function(x) {
  y <- x
  for (i in seq_along(x)) {
    y[i] <- if(x[i] <= 0) 0 else round(x[i])
  }
  y
}

```

```{r}
df <-Ecdat::Fair
str(df)
head(df)
```

```{r}
df$religious <- as.factor(df$religious)
df$occupation <- as.factor(df$occupation)
df$rate <- as.factor(df$rate)
levels(df$occupation) <- c("1", "2.5", "3", "4", "5", "6.5", "7")
df$occupation[df$occupation == 3] <- as.factor(2.5)
df$occupation[df$occupation == 7] <- as.factor(6.5)
df$occupation <- factor(df$occupation)
```

# Análise dos Dados

```{r}
summary(df)
```

```{r}
hist(df$age,main='The Histogram of Age',
     xlab='Age Values',prob=T)
lines(density(df$age,na.rm=T))
rug(df$age)

hist(df$ym,main='The Histogram of Years Married',
     xlab='Years Married',prob=T)
lines(density(df$ym,na.rm=T))
rug(df$ym)

hist(df$education,main='The Histogram of Education',
     xlab='Education (years)',prob=T)
lines(density(df$education,na.rm=T))
rug(df$education)

hist(df$nbaffairs,main='The Histogram of the Number of Affairs',
     xlab='Number of Affairs',prob=T)
lines(density(df$nbaffairs,na.rm=T))
rug(df$nbaffairs)
```

```{r}
par(mfrow=c(1,4))
boxplot(df$age, main="Age")
boxplot(df$ym, main="Years Married")
boxplot(df$education, main="Education")
boxplot(df$nbaffairs, main="Number of Affairs")
```

```{r}
par(mfrow=c(1,1))
boxplot(df$nbaffairs ~ df$sex, df, main="Number of affairs by sex")
boxplot(df$nbaffairs ~ df$child, df, main="Number of affairs by having children or not")  # ver p confundimento. -> Do modelo completo: childyes  coeficiente: -0.13303
boxplot(df$nbaffairs ~ df$religious, df, main="Number of affairs by level of religiosity")
boxplot(df$nbaffairs ~ df$occupation, df, main="Number of affairs by level of occupation")
boxplot(df$nbaffairs ~ df$rate, df, main="Number of affairs by level of self rating of marriage")
boxplot(df$nbaffairs ~ df$ym, df, main="Number of affairs by years married")
```

```{r}
ggplot(df,
       aes(x=age, y=nbaffairs,
           colour=sex
       )
) + geom_point()

ggplot(df,
       aes(x=religious, y=nbaffairs,
           colour=sex
       )
) + geom_point()

table(df$nbaffairs)
ggplot(df,aes(x=nbaffairs)) + geom_bar() + facet_wrap(~ sex) + ggtitle("Distribuition of affairs for individuals of different sexs")
table(df$sex)
ggplot(df,aes(x=nbaffairs)) + geom_bar() + facet_wrap(~ child) + ggtitle("Distribuition of affairs for individuals with and without children")
table(df$child)
ggplot(df,aes(x=nbaffairs)) + geom_bar() + facet_wrap(~ religious) + ggtitle("Distribuition of affairs for individuals of different religious levels")
table(df$religious)
ggplot(df,aes(x=nbaffairs)) + geom_bar() + facet_wrap(~ occupation) + ggtitle("Distribuition of affairs for individuals of different occupation levels")
table(df$occupation)
ggplot(df,aes(x=nbaffairs)) + geom_bar() + facet_wrap(~ rate) + ggtitle("Distribuition of affairs for different ratings of marriage")
table(df$rate)
```

Algumas notas relevantes:

- O dataset contem 601 observações

- A idade média é de ~32 anos e meio

- A proporção de individuos do sexo feminino é 0.524 e do sexo masculino é de 0.476

- 430 dos participantes têm filhos enquanto que 171 não têm.

- 451 não tiveram casos no último ano. 150 tiveram pelo menos um.

```{r}
dfChild <- df[as.character(df$child) == "yes", ]
table(dfChild$nbaffairs)
```

- dos q tem filhos (403), 123 tiveram casos e 307 não. Ou seja, approximadamente, 71% tiveram casos e 29% não.

```{r}
dfym10 <- df[as.character(df$ym) >= 10, ]
table(dfym10$nbaffairs)
```

```{r}
dfym10 <- df[as.character(df$ym) < 10, ]
table(dfym10$nbaffairs)
```

- dos casados há mais de 10 anos (461 indivíduos), 133 tiveram casos, ~29%.
- dos casados há menos de 10 anos (140 indivíduos), 17 tiveram casos, ~12%.


```{r}
corMatrix <- cor(df[, c("age", "ym", "education", "nbaffairs")])
corMatrix
corrplot(corMatrix, method="circle")
```

# Regressão Linear

## Regressão Linear Simples

```{r}
sex <- lm(nbaffairs ~ sex, df)
age <- lm(nbaffairs ~ age, df)
ym <- lm(nbaffairs ~ ym, df)
child<- lm(nbaffairs ~ child, df)
religious <- lm(nbaffairs ~ religious, df)
education <- lm(nbaffairs ~ education, df)
occupation <- lm(nbaffairs ~ occupation, df)
rate <- lm(nbaffairs ~ rate, df)
screenreg(list(sex, age, ym, child, religious, education, occupation, rate))
```

As regressões lineares simples parecem indicar que os coeficientes age, education e occupation são pouco significativos para prever o número de casos extraconjugais.

Estes modelos indicam-nos também que o indivíduo ser do sexo masculino causa um ligeiro incremento (0.08) no número de casos previstos. Um incremento de um ano de idade causa um aumento de 0.03 na previsão dos casos extraconjugais.

## Regrassão Linear Multipla

Diversos modelos foram testados, mas começando pelos mais simples, o modelo completo e o modelo nulo.

```{r}
modCompleto <- lm(nbaffairs ~ ., df)
summary(modCompleto)
```

Como se pode ver, o R2 ajustado é bastante baixo, 0.1342. Isto é explicado pelo facto de estarmos a prever um resultado discreto usando um modelo contínuo.

```{r}
modNulo <- lm(nbaffairs ~ 1, df)
summary(modNulo)
```

Como são modelos encaixados podemos compara-los usando a anova:

```{r}
anova(modCompleto, modNulo)
```

O valor-F é significativo. Rejeitamos por isso a hipotese nula de que o modelo pequeno explica tanto como o grande.

Vamos agora selecionar as variáveis significativas.

```{r}
drop1(modCompleto, test = "F")
```

Olhando para o output do drop1, as variáveis sex, child, education e occupation são candidatas a serem removidas pois o seu valor F não é significativo.



Vamos agora selecionar as variáveis significativas usando o método Backward no modelo completo, minimizando o AIC.

```{r}
modStep <- step(modCompleto, direction = c("backward"))
summary(modStep)
```

O resultado deste método foi a remoção das variáveis occupation, education, sex e child, pois a remoção de cada uma delas melhorou o AIC. Ficamos com as variáveis age, ym, religious e rate, todas elas significativas como se pode ver no summary.

Note-se também que o R2-ajustado melhorou um pouco.

Vamos agora comparar o modelo resultante com o modelo completo usando o anova.

```{r}
anova(modCompleto, modStep)
```

O valor-F não é significative, pelo que não rejeitamos a hipótese nula. O modelo com menos variáveis parece, efetivamente, explicar tanto quanto o completo.

## Efeitos de Interações

Podemos tentar melhorar o modelo através da introdução de interações entre variáveis.

```{r}
modI1 <- lm(nbaffairs ~ . -sex -child -education -occupation +ym:age, df)
summary(modI1)

# An interaction that improved the adjusted R2 by 4 was religious:rate
modI2 <- lm(nbaffairs ~ . -sex -child -education -occupation +religious:rate, df)
summary(modI2)

modI3 <- lm(nbaffairs ~ . -sex -child -education -occupation +religious:age, df)
summary(modI3)

modI4 <- lm(nbaffairs ~ . -sex -child -education -occupation +religious:age +religious:rate, df)
summary(modI4)

modStep <- step(modI4, direction = c("backward"))
summary(modStep)
drop1(modI4, test = "F")
AIC(modI4)
extractAIC(modI4, k=2)

modI5 <- lm(nbaffairs ~ . -age -sex -child -education -occupation +religious:age +religious:rate, df)
summary(modI5)
drop1(modI5, test = "F")
AIC(modI5)
extractAIC(modI5, k=2)

modI6 <- lm(nbaffairs ~ . -rate -age -sex -child -education -occupation +religious:age +religious:rate, df)
summary(modI6)
drop1(modI6, test = "F")
AIC(modI6)
extractAIC(modI6, k=2)

modI7 <- lm(nbaffairs ~ . -rate -age -sex -child -education -occupation +religious:ym +religious:age +religious:rate +occupation:rate +sex:occupation, df)
summary(modI7)
drop1(modI7, test = "F")
AIC(modI7)
extractAIC(modI7, k=2)
```

Podemos ver que as interações adicionadas melhoram bastante o modelo. O R2-ajustado ...

O AIC baixou de .... no modelo só com as variáveis significativas para ... 0.2433.



O modelo final de regressão linear que escolheriamos para este problema é o modI7. Este contém as explicativas ym e religious, bem como as interações ym:religious, age:religious.

Note que a remoção das variáveis age e rate não parece afectar o modelo com as duas interações, pelo que escolhemos deixá-las de fora. Assim obtemos um modelo mais simples, o que facilita a interpretação e minimiza o overfit.



```{r}
res = residuals(modI7)
boxplot(res)
RSS = sum(res^2)

predict(modI7, df, interval='c') # IC para a media
predict(modI7, df, interval='p') # IC de predicao. e' mais largo que o da media


res = rstandard(modI7)
boxplot(res)

plot(fitted.values(modI7), rstandard(modI7))


plot(hatvalues(modI7))

plot(rstandard(modI7))
plot(fitted.values(modI7))

qqPlot(rstandard(modI7))

pred1 <- predict(modI7,df)
pred1
plot(pred1)

round.pred <- smart.round(pred1)
round.pred

mse <- mean((round.pred - df$nbaffairs)^2)
mse

mae <- mean(abs(round.pred - df$nbaffairs))
mae
```



Para garantir que a introdução das novas variáveis não causou overfit, iremos usar cross-validation, testanto o modelo num conjunto de dados diferente do de treino. O training set terá 70% dos dados do dataset original e o testing set os restantes 30%.

```{r}
trainingRows <- sample(1:nrow(df), 0.7*nrow(df))
training <- df[trainingRows,]
testing <- df[-trainingRows,]

modI7 <- lm(nbaffairs ~ . -rate -age -sex -child -education -occupation +religious:ym +religious:age +religious:rate +occupation:rate +sex:occupation, training)

predictions <- predict(modI7,testing)
predictions <- smart.round(predictions)
mse <- mean((predictions - testing$nbaffairs)^2)
mse

mae <- mean(abs(predictions - testing$nbaffairs))
mae


predictions <- predict(modI7,training)
mse <- mean((predictions - training$nbaffairs)^2)
mse

mae <- mean(abs(predictions - training$nbaffairs))
mae

```

The error is high as expected, but it is equivalent in the testing and training sets so there is no overfitting.

```{r}
summary(modI7)
```

Para responder às questões do enunciado, escolhemos a variável numérica ym e a categórica religious.

c) i) faça a interpretação dos correspondentes efeitos brutos e ajustados

```{r}
ym <- lm(nbaffairs ~ ym, df)
summary(ym)
```

O efeito bruto de ym: para cada incremento no número de anos casados, número de casos extraconjugais aumenta 0.11063.
O efeito ajustado de ym: para cada incremento no número de anos casados, número de casos extraconjugais aumenta 0.06846, quando fixadas as restantes variáveis.

```{r}
religious <- lm(nbaffairs ~ religious, df)
summary(religious)
```

Relembrando, a escala da variável religious, é de 1 - nada religioso, 2 - pouco religioso, 3 - moderado, 4 - religioso, 5 - muito religioso.

O efeito bruto de religious: -0.9309 é o decremento do número de casos extraconjugais ao passar de nada religioso para pouco religioso.
O efeito ajustado de religious: 0.20279 é o incremento do número de casos extraconjugais ao passar de nada religioso para pouco religioso, quando fixados os valores das outras covariáveis.

A mesma interpretação deve ser feita para os restantes níveis da variável religious. Ou seja, passar de:
- moderado para nada religioso: efeito bruto de -0.6066 e efeito ajustado: 7.37466
- religioso para nada religioso: efeito bruto de -1.7254 e efeito ajustado: 2.00127
- muito religioso para nada religioso: efeito bruto de -1.6976 e efeito ajustado: -2.75653

É de notar que muitos dos efeitos trocam de sinal. Isso pode indicar um factor de confundimento.


ii) interprete o efeito provocado na resposta por uma mudança da terceira categoria de X2 para a segunda, assim como intervalos de confiança a 95% e a 90% para esse efeito.

```{r}
df$religious <- relevel(df$religious, ref = 3)
levels(df$religious)

modI7 <- lm(nbaffairs ~ . -rate -age -sex -child -education -occupation +religious:ym +religious:age +religious:rate +occupation:rate +sex:occupation, df)
summary(modI7)
```

```{r}
religious <- lm(nbaffairs ~ religious, df)
summary(religious)
```

Uma mudança de pouco religioso para moderado tem um grande efeito ajustado, onde o decremento é de -8.73734 para o número de casos extraconjugais, quando fixados os valores das outras covariáveis. Já no efeito bruto, tem-se um decremento de -0.3243. 

```{r}
confint(modI7, level = 0.95)
```

O intervalo de confiança a 95% é de [-14.037852034, -3.43682449].


```{r}
confint(modI7, level = 0.90)
```

O intervalo de confiança a 90% é de [-13.18333111, -4.291345411].

```{r}
df$religious <- relevel(df$religious, ref = 1)
```

iii) 

```{r}
(max(df$ym) - min(df$ym)) * 0.2

modSignif <- lm(nbaffairs ~ age+ym+religious+rate, df)
summary(modSignif)

mod20ym <- lm(nbaffairs ~ age+I(2.975*ym)+religious+rate, df)
summary(mod20ym)
```

....

iv) averigue a existência de uma interação significativa entre X1 e X2

Esta interação estava já a ser considerada, mas vamos analisá-la mais formalmente.
Para isso, vamos usar o modelo completo:

```{r}
modCompleto <- lm(nbaffairs ~ ., df)
summary(modCompleto)
```

```{r}
modInteracao <- lm(nbaffairs ~ . +ym:religious, df)
summary(modInteracao)
```

Podemos ver que o R2-ajustado melhorou com a introdução da interação. Vamos comparar utilizando a anova, ???

```{r}
anova(modInteracao, modCompleto)
```

O modelo com interação é significativo ao nível 0.05. ????

v) considerando o modelo com apenas estas duas variáveis explicativas, indique um intervalo de predição a 95% para um indivíduo no primeiro quartil de X1 e da segunda categoria de X2.

```{r}
mod <- lm(nbaffairs ~ ym + religious, df)
summary(mod)
```

```{r}
quantile(df$ym,0.25)
boxplot(df$ym, main="Years Married")
predict(mod, data.frame(ym=1,religious=as.factor(2)), i="c")
predict(mod, data.frame(ym=1,religious=as.factor(2)), i="p")
```

# Regressão Logística

```{r}
df2 <- df
df2$nbaffairs <- df$nbaffairs != 0
df2$nbaffairs <- as.numeric(df2$nbaffairs)
df2$nbaffairs <- as.factor(df2$nbaffairs)
df2
table(df2$nbaffairs)
```


Vamos, mais uma vez, começar por analisar os modelos completo e nulo, e compará-los. Desta vez, vamos fazê-lo "à mão", utilizando o drop1, em vez de com o step.

```{r}
modCompleto <- glm(nbaffairs ~ . , family = binomial(), df2)
summary(modCompleto)
```

```{r}
modNulo <- glm(nbaffairs ~ 1 , family = binomial(), df2)
summary(modNulo)
```

```{r}
anova(modCompleto, modNulo)
```

Vamos agora tentar encontrar o melhor modelo.

```{r}
drop1(mod, test = "Chisq")
```

```{r}
mod1 <- glm(nbaffairs ~ . -sex , family = binomial(), df2)
summary(mod1)
```

```{r}
anova(modCompleto, mod1)
```

```{r}
drop1(mod1, test = "Chisq")
```

```{r}
mod2 <- glm(nbaffairs ~ . -sex -education, family = binomial(), df2)
summary(mod2)
```

```{r}
anova(modCompleto, mod2)
```

```{r}
drop1(mod2, test = "Chisq")
```

```{r}
mod3 <- glm(nbaffairs ~ . -sex -education -child, family = binomial(), df2)
summary(mod3)
```

```{r}
anova(modCompleto, mod3)
```

```{r}
drop1(mod3, test = "Chisq")
```

```{r}
mod4 <- glm(nbaffairs ~ . -sex -education -child -occupation, family = binomial(), df2)
summary(mod4)
```

```{r}
anova(modCompleto, mod4)
```

```{r}
drop1(mod4, test = "Chisq")
```

Agora já todas as variáveis são significativas.

Podemos ainda tentar adicionar interações como na regressão linear.

<!-- The formula chosen for the lm model was:

nbaffairs ~. -rate -age -sex -child -education -occupation +religious:ym +religious:age +religious:rate +occupation:rate +sex:occupation

-->
```{r}
modI <- glm(nbaffairs ~ . -sex -education -child -occupation +occupation:rate, family = binomial(), df2)
summary(modI)
```

```{r}
anova(modCompleto, modI)
```

Cada uma das interações que usamos no modelo linear foi testada neste modelo, assim como o conjunto delas. Em cada um dos casos, o AIC só aumentou, pelo que nenhuma será adicionada ao modelo logístico.

O modelo final é constituido pelas variáveis explicativas: age, ym, religious e rate.

```{r}
summary(mod4)
```


b) para uma variável contínua X1 e uma categórica com mais de duas categorias X2 que constem do modelo final (ou do modelo inicial no caso do final não ter este tipo de variáveis):

Usaremos as variáveis ym e rate por serem as mais significativas de cada tipo.

i) faça a interpretação dos correspondentes efeitos brutos e ajustados;

```{r}
ym <- glm(nbaffairs ~ ym, family = binomial(), df2)
summary(ym)
```

O efeito bruto de ym: e^0.05882 é o odds ratio do número de anos casado para o número de casos extraconjugais.
O efeito ajustado de ym: e^0.09815 é o odds ratio do número de anos casado para o número de casos extraconjugais, quando fixados os valores das outras covariáveis.

```{r}
rate <- glm(nbaffairs ~ rate, family = binomial(), df2)
summary(rate)
```

O efeito bruto de rate: e^9.379e-15 é o odds ratio de dar um rate de 2 ao seu casamento (versus um rate de 1) para o número de casos extraconjugais. Esse efeito é muito pequeno e muito pouco significativo. Há medida que os rates aumentam, os seus efeitos são mais significativos e no sentido inverso. Ou seja, um rate alto indicia a ausência de casos extraconjugais.
Os efeitos brutos de passar de um rate de 1 para 3, 4 e 5 são de -8.938e-01, -1.112e+00 e -1.762e+00, respectivamente, e seguem a mesma interpretação que acima.

O efeito ajustado de rate: e^0.15157 é o odds ratio de dar um rate de 2 ao seu casamento (versus um rate de 1) para o número de casos extraconjugais, quando fixados os valores das outras covariáveis. Os efeito ajustado de passar de 3 para 1 é de -0.71324, de 1 para 4 é de -0.97987 e de 1 para 5 é de -1.53310.

ii) interprete o efeito provocado por um aumento em X1 correspondente
a 20% da amplitude dos seus valores;

```{r}
rate <- glm(nbaffairs ~ rate, family = binomial(), df2)
summary(rate)
```

```{r}
(max(df$ym) - min(df$ym)) * 0.2

modSignif <- glm(nbaffairs ~ age+ym+religious+rate, family = binomial(), df2)
summary(modSignif)

mod20ym <- glm(nbaffairs ~ age+I(2.975*ym)+religious+rate, family = binomial(), df2)
summary(mod20ym)
```

iii) averigue a existência de uma interação significativa entre X1 e X2.

Esta interação estava já a ser considerada, mas vamos analisá-la mais formalmente.
Para isso, vamos usar o modelo completo:

```{r}
modCompleto <- glm(nbaffairs ~ ., family = binomial(), df2)
summary(modCompleto)
```

```{r}
modInteracao <- glm(nbaffairs ~ . +ym:rate, family = binomial(), df2)
summary(modInteracao)
```

Podemos ver que o AIC piorou com a introdução da interação. Vamos comparar utilizando a anova, ???

```{r}
anova(modInteracao, modCompleto)
```

O modelo com interação é significativo ????



# Conclusões

Numa situação normal este tipo de dados não seria modelado usando regressão linear, mas sim com outro tipo de regressão.

Os resultados obtidos com este método não são muito bons mesmo usando as diversas técnicas de otimização ao nosso dispor.

Apesar disso, é possível tirar algumas conclusões. Nomeadamente, que as variáveis com mais peso para esta tarefa de previsão são a idade, o número de anos casado, quão religioso o indivíduo é e o rating que dá ao seu casamento. No caso da regressão linear, mais 1 ano de idade diminuiu em 0.04222 o número de casos previstos, mais 1 ano de casado aumenta,  

```{r}
mod4 <- lm(nbaffairs ~ . -sex -education -child -occupation, df)
summary(mod4)
```

